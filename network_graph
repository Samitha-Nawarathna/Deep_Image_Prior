digraph {
	graph [size="112.35,112.35"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	1967077411808 [label="
 (1, 3, 512, 512)" fillcolor=darkolivegreen1]
	1964973479904 [label=SigmoidBackward0]
	1964973209168 -> 1964973479904
	1964973209168 [label=BackwardHookFunctionBackward]
	1964973481488 -> 1964973209168
	1964973481488 [label=ConvolutionBackward0]
	1964973208912 -> 1964973481488
	1964973208912 [label=BackwardHookFunctionBackward]
	1964973533472 -> 1964973208912
	1964973533472 [label=UpsampleNearest2DBackward0]
	1964973449248 -> 1964973533472
	1964973449248 [label=LeakyReluBackward1]
	1964973447856 -> 1964973449248
	1964973447856 [label=NativeBatchNormBackward0]
	1964973208656 -> 1964973447856
	1964973208656 [label=BackwardHookFunctionBackward]
	1964973438384 -> 1964973208656
	1964973438384 [label=ConvolutionBackward0]
	1964973208400 -> 1964973438384
	1964973208400 [label=BackwardHookFunctionBackward]
	1964973428064 -> 1964973208400
	1964973428064 [label=LeakyReluBackward1]
	1964973426096 -> 1964973428064
	1964973426096 [label=NativeBatchNormBackward0]
	1964973208144 -> 1964973426096
	1964973208144 [label=BackwardHookFunctionBackward]
	1964973515168 -> 1964973208144
	1964973515168 [label=ConvolutionBackward0]
	1964973207888 -> 1964973515168
	1964973207888 [label=BackwardHookFunctionBackward]
	1964973515216 -> 1964973207888
	1964973515216 [label=NativeBatchNormBackward0]
	1964973519440 -> 1964973515216
	1964973519440 [label=UpsampleNearest2DBackward0]
	1964973520016 -> 1964973519440
	1964973520016 [label=LeakyReluBackward1]
	1964973518528 -> 1964973520016
	1964973518528 [label=NativeBatchNormBackward0]
	1964973207632 -> 1964973518528
	1964973207632 [label=BackwardHookFunctionBackward]
	1964973511808 -> 1964973207632
	1964973511808 [label=ConvolutionBackward0]
	1964973207376 -> 1964973511808
	1964973207376 [label=BackwardHookFunctionBackward]
	1964973512048 -> 1964973207376
	1964973512048 [label=LeakyReluBackward1]
	1964973516368 -> 1964973512048
	1964973516368 [label=NativeBatchNormBackward0]
	1964973207120 -> 1964973516368
	1964973207120 [label=BackwardHookFunctionBackward]
	1964973520832 -> 1964973207120
	1964973520832 [label=ConvolutionBackward0]
	1964973206864 -> 1964973520832
	1964973206864 [label=BackwardHookFunctionBackward]
	1964973520304 -> 1964973206864
	1964973520304 [label=NativeBatchNormBackward0]
	1964973500416 -> 1964973520304
	1964973500416 [label=UpsampleNearest2DBackward0]
	1964973501808 -> 1964973500416
	1964973501808 [label=LeakyReluBackward1]
	1964973496048 -> 1964973501808
	1964973496048 [label=NativeBatchNormBackward0]
	1964973206608 -> 1964973496048
	1964973206608 [label=BackwardHookFunctionBackward]
	1964973497824 -> 1964973206608
	1964973497824 [label=ConvolutionBackward0]
	1964973206352 -> 1964973497824
	1964973206352 [label=BackwardHookFunctionBackward]
	1964973505840 -> 1964973206352
	1964973505840 [label=LeakyReluBackward1]
	1964973495136 -> 1964973505840
	1964973495136 [label=NativeBatchNormBackward0]
	1964973206096 -> 1964973495136
	1964973206096 [label=BackwardHookFunctionBackward]
	1964973501568 -> 1964973206096
	1964973501568 [label=ConvolutionBackward0]
	1964973205840 -> 1964973501568
	1964973205840 [label=BackwardHookFunctionBackward]
	1964973502288 -> 1964973205840
	1964973502288 [label=NativeBatchNormBackward0]
	1964973496672 -> 1964973502288
	1964973496672 [label=UpsampleNearest2DBackward0]
	1964973494704 -> 1964973496672
	1964973494704 [label=LeakyReluBackward1]
	1964973506272 -> 1964973494704
	1964973506272 [label=NativeBatchNormBackward0]
	1964973205584 -> 1964973506272
	1964973205584 [label=BackwardHookFunctionBackward]
	1964973506080 -> 1964973205584
	1964973506080 [label=ConvolutionBackward0]
	1964973205328 -> 1964973506080
	1964973205328 [label=BackwardHookFunctionBackward]
	1964973505696 -> 1964973205328
	1964973505696 [label=LeakyReluBackward1]
	1964973461312 -> 1964973505696
	1964973461312 [label=NativeBatchNormBackward0]
	1964973205072 -> 1964973461312
	1964973205072 [label=BackwardHookFunctionBackward]
	1964973460688 -> 1964973205072
	1964973460688 [label=ConvolutionBackward0]
	1964973204816 -> 1964973460688
	1964973204816 [label=BackwardHookFunctionBackward]
	1964973471296 -> 1964973204816
	1964973471296 [label=NativeBatchNormBackward0]
	1964973466928 -> 1964973471296
	1964973466928 [label=UpsampleNearest2DBackward0]
	1964973462608 -> 1964973466928
	1964973462608 [label=LeakyReluBackward1]
	1964973459776 -> 1964973462608
	1964973459776 [label=NativeBatchNormBackward0]
	1964973204560 -> 1964973459776
	1964973204560 [label=BackwardHookFunctionBackward]
	1964973461072 -> 1964973204560
	1964973461072 [label=ConvolutionBackward0]
	1964973204304 -> 1964973461072
	1964973204304 [label=BackwardHookFunctionBackward]
	1964973469088 -> 1964973204304
	1964973469088 [label=LeakyReluBackward1]
	1964973473216 -> 1964973469088
	1964973473216 [label=NativeBatchNormBackward0]
	1964973204048 -> 1964973473216
	1964973204048 [label=BackwardHookFunctionBackward]
	1964973467936 -> 1964973204048
	1964973467936 [label=ConvolutionBackward0]
	1964973203792 -> 1964973467936
	1964973203792 [label=BackwardHookFunctionBackward]
	1964973466832 -> 1964973203792
	1964973466832 [label=NativeBatchNormBackward0]
	1964973463088 -> 1964973466832
	1964973463088 [label=UpsampleNearest2DBackward0]
	1964973464816 -> 1964973463088
	1964973464816 [label=LeakyReluBackward1]
	1964973468368 -> 1964973464816
	1964973468368 [label=NativeBatchNormBackward0]
	1964973203536 -> 1964973468368
	1964973203536 [label=BackwardHookFunctionBackward]
	1964973465440 -> 1964973203536
	1964973465440 [label=ConvolutionBackward0]
	1964973203280 -> 1964973465440
	1964973203280 [label=BackwardHookFunctionBackward]
	1964973558416 -> 1964973203280
	1964973558416 [label=LeakyReluBackward1]
	1964973558368 -> 1964973558416
	1964973558368 [label=NativeBatchNormBackward0]
	1964973203024 -> 1964973558368
	1964973203024 [label=BackwardHookFunctionBackward]
	1964973563888 -> 1964973203024
	1964973563888 [label=ConvolutionBackward0]
	1964973202768 -> 1964973563888
	1964973202768 [label=BackwardHookFunctionBackward]
	1964973562496 -> 1964973202768
	1964973562496 [label=NativeBatchNormBackward0]
	1964973559760 -> 1964973562496
	1964973559760 [label=LeakyReluBackward1]
	1964973559472 -> 1964973559760
	1964973559472 [label=NativeBatchNormBackward0]
	1964973202512 -> 1964973559472
	1964973202512 [label=BackwardHookFunctionBackward]
	1964973557504 -> 1964973202512
	1964973557504 [label=ConvolutionBackward0]
	1964973202256 -> 1964973557504
	1964973202256 [label=BackwardHookFunctionBackward]
	1964973555968 -> 1964973202256
	1964973555968 [label=LeakyReluBackward1]
	1964973561248 -> 1964973555968
	1964973561248 [label=NativeBatchNormBackward0]
	1964973202000 -> 1964973561248
	1964973202000 [label=BackwardHookFunctionBackward]
	1964973562064 -> 1964973202000
	1964973562064 [label=ConvolutionBackward0]
	1964973201744 -> 1964973562064
	1964973201744 [label=BackwardHookFunctionBackward]
	1964973562160 -> 1964973201744
	1964973562160 [label=LeakyReluBackward1]
	1964973558128 -> 1964973562160
	1964973558128 [label=NativeBatchNormBackward0]
	1964973557072 -> 1964973558128
	1964973557072 [label=AvgPool2DBackward0]
	1964973201488 -> 1964973557072
	1964973201488 [label=BackwardHookFunctionBackward]
	1964973563264 -> 1964973201488
	1964973563264 [label=ConvolutionBackward0]
	1964973201232 -> 1964973563264
	1964973201232 [label=BackwardHookFunctionBackward]
	1964973563696 -> 1964973201232
	1964973563696 [label=LeakyReluBackward1]
	1964973558224 -> 1964973563696
	1964973558224 [label=NativeBatchNormBackward0]
	1964973200976 -> 1964973558224
	1964973200976 [label=BackwardHookFunctionBackward]
	1964973559040 -> 1964973200976
	1964973559040 [label=ConvolutionBackward0]
	1964973200720 -> 1964973559040
	1964973200720 [label=BackwardHookFunctionBackward]
	1964973563936 -> 1964973200720
	1964973563936 [label=LeakyReluBackward1]
	1964973558992 -> 1964973563936
	1964973558992 [label=NativeBatchNormBackward0]
	1964973564512 -> 1964973558992
	1964973564512 [label=AvgPool2DBackward0]
	1964973200464 -> 1964973564512
	1964973200464 [label=BackwardHookFunctionBackward]
	1964973557024 -> 1964973200464
	1964973557024 [label=ConvolutionBackward0]
	1964973200208 -> 1964973557024
	1964973200208 [label=BackwardHookFunctionBackward]
	1964973564944 -> 1964973200208
	1964973564944 [label=LeakyReluBackward1]
	1964973564320 -> 1964973564944
	1964973564320 [label=NativeBatchNormBackward0]
	1964973199952 -> 1964973564320
	1964973199952 [label=BackwardHookFunctionBackward]
	1964973560240 -> 1964973199952
	1964973560240 [label=ConvolutionBackward0]
	1964973199696 -> 1964973560240
	1964973199696 [label=BackwardHookFunctionBackward]
	1964973562880 -> 1964973199696
	1964973562880 [label=LeakyReluBackward1]
	1964973562688 -> 1964973562880
	1964973562688 [label=NativeBatchNormBackward0]
	1964973559136 -> 1964973562688
	1964973559136 [label=AvgPool2DBackward0]
	1964973199440 -> 1964973559136
	1964973199440 [label=BackwardHookFunctionBackward]
	1964973565232 -> 1964973199440
	1964973565232 [label=ConvolutionBackward0]
	1964973199184 -> 1964973565232
	1964973199184 [label=BackwardHookFunctionBackward]
	1964973565472 -> 1964973199184
	1964973565472 [label=LeakyReluBackward1]
	1964973565568 -> 1964973565472
	1964973565568 [label=NativeBatchNormBackward0]
	1964973198928 -> 1964973565568
	1964973198928 [label=BackwardHookFunctionBackward]
	1964973565808 -> 1964973198928
	1964973565808 [label=ConvolutionBackward0]
	1964973198672 -> 1964973565808
	1964973198672 [label=BackwardHookFunctionBackward]
	1964973566048 -> 1964973198672
	1964973566048 [label=LeakyReluBackward1]
	1964973566144 -> 1964973566048
	1964973566144 [label=NativeBatchNormBackward0]
	1964973566240 -> 1964973566144
	1964973566240 [label=AvgPool2DBackward0]
	1964973198416 -> 1964973566240
	1964973198416 [label=BackwardHookFunctionBackward]
	1964973566480 -> 1964973198416
	1964973566480 [label=ConvolutionBackward0]
	1964973197136 -> 1964973566480
	1964973197136 [label=BackwardHookFunctionBackward]
	1964973566720 -> 1964973197136
	1964973566720 [label=LeakyReluBackward1]
	1964973566816 -> 1964973566720
	1964973566816 [label=NativeBatchNormBackward0]
	1964973197904 -> 1964973566816
	1964973197904 [label=BackwardHookFunctionBackward]
	1964973567056 -> 1964973197904
	1964973567056 [label=ConvolutionBackward0]
	1964973210960 -> 1964973567056
	1964973210960 [label=BackwardHookFunctionBackward]
	1964973567296 -> 1964973210960
	1964973567296 [label=LeakyReluBackward1]
	1964973567392 -> 1964973567296
	1964973567392 [label=NativeBatchNormBackward0]
	1964973567488 -> 1964973567392
	1964973567488 [label=AvgPool2DBackward0]
	1964973211216 -> 1964973567488
	1964973211216 [label=BackwardHookFunctionBackward]
	1964973567728 -> 1964973211216
	1964973567728 [label=ConvolutionBackward0]
	1964972095568 -> 1964973567728
	1964972095568 [label=BackwardHookFunctionBackward]
	1964973567968 -> 1964972095568
	1964973567968 [label=LeakyReluBackward1]
	1964973568064 -> 1964973567968
	1964973568064 [label=NativeBatchNormBackward0]
	1964972095312 -> 1964973568064
	1964972095312 [label=BackwardHookFunctionBackward]
	1964973568304 -> 1964972095312
	1964973568304 [label=ConvolutionBackward0]
	1964972094800 -> 1964973568304
	1964972094800 [label=BackwardHookFunctionBackward]
	1964973568544 -> 1964972094800
	1964973568544 [label=LeakyReluBackward1]
	1964973568640 -> 1964973568544
	1964973568640 [label=NativeBatchNormBackward0]
	1964973568736 -> 1964973568640
	1964973568736 [label=AvgPool2DBackward0]
	1964972095824 -> 1964973568736
	1964972095824 [label=BackwardHookFunctionBackward]
	1964973568976 -> 1964972095824
	1964973568976 [label=ConvolutionBackward0]
	1964973569072 -> 1964973568976
	1966963632448 [label="encoders.0.0.weight
 (16, 3, 5, 5)" fillcolor=lightblue]
	1966963632448 -> 1964973569072
	1964973569072 [label=AccumulateGrad]
	1964973569024 -> 1964973568976
	1966963632368 [label="encoders.0.0.bias
 (16)" fillcolor=lightblue]
	1966963632368 -> 1964973569024
	1964973569024 [label=AccumulateGrad]
	1964973568688 -> 1964973568640
	1967043821888 [label="encoders.0.2.0.weight
 (16)" fillcolor=lightblue]
	1967043821888 -> 1964973568688
	1964973568688 [label=AccumulateGrad]
	1964973568448 -> 1964973568640
	1966963632608 [label="encoders.0.2.0.bias
 (16)" fillcolor=lightblue]
	1966963632608 -> 1964973568448
	1964973568448 [label=AccumulateGrad]
	1964973568400 -> 1964973568304
	1966963637888 [label="encoders.0.3.0.weight
 (16, 16, 5, 5)" fillcolor=lightblue]
	1966963637888 -> 1964973568400
	1964973568400 [label=AccumulateGrad]
	1964973568352 -> 1964973568304
	1966963637808 [label="encoders.0.3.0.bias
 (16)" fillcolor=lightblue]
	1966963637808 -> 1964973568352
	1964973568352 [label=AccumulateGrad]
	1964973568160 -> 1964973568064
	1966963637728 [label="encoders.0.3.1.0.weight
 (16)" fillcolor=lightblue]
	1966963637728 -> 1964973568160
	1964973568160 [label=AccumulateGrad]
	1964973568112 -> 1964973568064
	1966963637648 [label="encoders.0.3.1.0.bias
 (16)" fillcolor=lightblue]
	1966963637648 -> 1964973568112
	1964973568112 [label=AccumulateGrad]
	1964973567824 -> 1964973567728
	1966963627488 [label="encoders.1.0.weight
 (32, 16, 5, 5)" fillcolor=lightblue]
	1966963627488 -> 1964973567824
	1964973567824 [label=AccumulateGrad]
	1964973567776 -> 1964973567728
	1966963627648 [label="encoders.1.0.bias
 (32)" fillcolor=lightblue]
	1966963627648 -> 1964973567776
	1964973567776 [label=AccumulateGrad]
	1964973567440 -> 1964973567392
	1966963627568 [label="encoders.1.2.0.weight
 (32)" fillcolor=lightblue]
	1966963627568 -> 1964973567440
	1964973567440 [label=AccumulateGrad]
	1964973567200 -> 1964973567392
	1966963622768 [label="encoders.1.2.0.bias
 (32)" fillcolor=lightblue]
	1966963622768 -> 1964973567200
	1964973567200 [label=AccumulateGrad]
	1964973567152 -> 1964973567056
	1966963691584 [label="encoders.1.3.0.weight
 (32, 32, 5, 5)" fillcolor=lightblue]
	1966963691584 -> 1964973567152
	1964973567152 [label=AccumulateGrad]
	1964973567104 -> 1964973567056
	1966963691504 [label="encoders.1.3.0.bias
 (32)" fillcolor=lightblue]
	1966963691504 -> 1964973567104
	1964973567104 [label=AccumulateGrad]
	1964973566912 -> 1964973566816
	1966963698144 [label="encoders.1.3.1.0.weight
 (32)" fillcolor=lightblue]
	1966963698144 -> 1964973566912
	1964973566912 [label=AccumulateGrad]
	1964973566864 -> 1964973566816
	1966963698064 [label="encoders.1.3.1.0.bias
 (32)" fillcolor=lightblue]
	1966963698064 -> 1964973566864
	1964973566864 [label=AccumulateGrad]
	1964973566576 -> 1964973566480
	1966963691104 [label="encoders.2.0.weight
 (64, 32, 5, 5)" fillcolor=lightblue]
	1966963691104 -> 1964973566576
	1964973566576 [label=AccumulateGrad]
	1964973566528 -> 1964973566480
	1966963697824 [label="encoders.2.0.bias
 (64)" fillcolor=lightblue]
	1966963697824 -> 1964973566528
	1964973566528 [label=AccumulateGrad]
	1964973566192 -> 1964973566144
	1966963697744 [label="encoders.2.2.0.weight
 (64)" fillcolor=lightblue]
	1966963697744 -> 1964973566192
	1964973566192 [label=AccumulateGrad]
	1964973565952 -> 1964973566144
	1966963691024 [label="encoders.2.2.0.bias
 (64)" fillcolor=lightblue]
	1966963691024 -> 1964973565952
	1964973565952 [label=AccumulateGrad]
	1964973565904 -> 1964973565808
	1966963697504 [label="encoders.2.3.0.weight
 (64, 64, 5, 5)" fillcolor=lightblue]
	1966963697504 -> 1964973565904
	1964973565904 [label=AccumulateGrad]
	1964973565856 -> 1964973565808
	1966963697424 [label="encoders.2.3.0.bias
 (64)" fillcolor=lightblue]
	1966963697424 -> 1964973565856
	1964973565856 [label=AccumulateGrad]
	1964973565664 -> 1964973565568
	1966963690704 [label="encoders.2.3.1.0.weight
 (64)" fillcolor=lightblue]
	1966963690704 -> 1964973565664
	1964973565664 [label=AccumulateGrad]
	1964973565616 -> 1964973565568
	1966963690624 [label="encoders.2.3.1.0.bias
 (64)" fillcolor=lightblue]
	1966963690624 -> 1964973565616
	1964973565616 [label=AccumulateGrad]
	1964973565328 -> 1964973565232
	1966963697104 [label="encoders.3.0.weight
 (128, 64, 5, 5)" fillcolor=lightblue]
	1966963697104 -> 1964973565328
	1964973565328 [label=AccumulateGrad]
	1964973565280 -> 1964973565232
	1966963703744 [label="encoders.3.0.bias
 (128)" fillcolor=lightblue]
	1966963703744 -> 1964973565280
	1964973565280 [label=AccumulateGrad]
	1964973565040 -> 1964973562688
	1966963703664 [label="encoders.3.2.0.weight
 (128)" fillcolor=lightblue]
	1966963703664 -> 1964973565040
	1964973565040 [label=AccumulateGrad]
	1964973557408 -> 1964973562688
	1966963690224 [label="encoders.3.2.0.bias
 (128)" fillcolor=lightblue]
	1966963690224 -> 1964973557408
	1964973557408 [label=AccumulateGrad]
	1964973557456 -> 1964973560240
	1966963697024 [label="encoders.3.3.0.weight
 (128, 128, 5, 5)" fillcolor=lightblue]
	1966963697024 -> 1964973557456
	1964973557456 [label=AccumulateGrad]
	1964973556400 -> 1964973560240
	1966963696944 [label="encoders.3.3.0.bias
 (128)" fillcolor=lightblue]
	1966963696944 -> 1964973556400
	1964973556400 [label=AccumulateGrad]
	1964973560528 -> 1964973564320
	1966963703584 [label="encoders.3.3.1.0.weight
 (128)" fillcolor=lightblue]
	1966963703584 -> 1964973560528
	1964973560528 [label=AccumulateGrad]
	1964973560000 -> 1964973564320
	1966963703504 [label="encoders.3.3.1.0.bias
 (128)" fillcolor=lightblue]
	1966963703504 -> 1964973560000
	1964973560000 [label=AccumulateGrad]
	1964973564128 -> 1964973557024
	1966963703344 [label="encoders.4.0.weight
 (128, 128, 5, 5)" fillcolor=lightblue]
	1966963703344 -> 1964973564128
	1964973564128 [label=AccumulateGrad]
	1964973559712 -> 1964973557024
	1966963689904 [label="encoders.4.0.bias
 (128)" fillcolor=lightblue]
	1966963689904 -> 1964973559712
	1964973559712 [label=AccumulateGrad]
	1964973561872 -> 1964973558992
	1966963689824 [label="encoders.4.2.0.weight
 (128)" fillcolor=lightblue]
	1966963689824 -> 1964973561872
	1964973561872 [label=AccumulateGrad]
	1964973560192 -> 1964973558992
	1966963696544 [label="encoders.4.2.0.bias
 (128)" fillcolor=lightblue]
	1966963696544 -> 1964973560192
	1964973560192 [label=AccumulateGrad]
	1964973563312 -> 1964973559040
	1966963689664 [label="encoders.4.3.0.weight
 (128, 128, 5, 5)" fillcolor=lightblue]
	1966963689664 -> 1964973563312
	1964973563312 [label=AccumulateGrad]
	1964973561920 -> 1964973559040
	1966963696384 [label="encoders.4.3.0.bias
 (128)" fillcolor=lightblue]
	1966963696384 -> 1964973561920
	1964973561920 [label=AccumulateGrad]
	1964973561776 -> 1964973558224
	1966963696304 [label="encoders.4.3.1.0.weight
 (128)" fillcolor=lightblue]
	1966963696304 -> 1964973561776
	1964973561776 [label=AccumulateGrad]
	1964973560576 -> 1964973558224
	1966963703104 [label="encoders.4.3.1.0.bias
 (128)" fillcolor=lightblue]
	1966963703104 -> 1964973560576
	1964973560576 [label=AccumulateGrad]
	1964973559424 -> 1964973563264
	1966963702944 [label="encoders.5.0.weight
 (128, 128, 5, 5)" fillcolor=lightblue]
	1966963702944 -> 1964973559424
	1964973559424 [label=AccumulateGrad]
	1964973562016 -> 1964973563264
	1966963702864 [label="encoders.5.0.bias
 (128)" fillcolor=lightblue]
	1966963702864 -> 1964973562016
	1964973562016 [label=AccumulateGrad]
	1964973564272 -> 1964973558128
	1966963689424 [label="encoders.5.2.0.weight
 (128)" fillcolor=lightblue]
	1966963689424 -> 1964973564272
	1964973564272 [label=AccumulateGrad]
	1964973565088 -> 1964973558128
	1966963689344 [label="encoders.5.2.0.bias
 (128)" fillcolor=lightblue]
	1966963689344 -> 1964973565088
	1964973565088 [label=AccumulateGrad]
	1964973563792 -> 1964973562064
	1966963689184 [label="encoders.5.3.0.weight
 (128, 128, 5, 5)" fillcolor=lightblue]
	1966963689184 -> 1964973563792
	1964973563792 [label=AccumulateGrad]
	1964973562736 -> 1964973562064
	1966963695904 [label="encoders.5.3.0.bias
 (128)" fillcolor=lightblue]
	1966963695904 -> 1964973562736
	1964973562736 [label=AccumulateGrad]
	1964973556736 -> 1964973561248
	1966963695824 [label="encoders.5.3.1.0.weight
 (128)" fillcolor=lightblue]
	1966963695824 -> 1964973556736
	1964973556736 [label=AccumulateGrad]
	1964973563168 -> 1964973561248
	1966963702624 [label="encoders.5.3.1.0.bias
 (128)" fillcolor=lightblue]
	1966963702624 -> 1964973563168
	1964973563168 [label=AccumulateGrad]
	1964973563552 -> 1964973557504
	1966963695664 [label="bottleneck.0.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	1966963695664 -> 1964973563552
	1964973563552 [label=AccumulateGrad]
	1964973557216 -> 1964973557504
	1966963702464 [label="bottleneck.0.bias
 (128)" fillcolor=lightblue]
	1966963702464 -> 1964973557216
	1964973557216 [label=AccumulateGrad]
	1964973563600 -> 1964973559472
	1966963702384 [label="bottleneck.1.0.weight
 (128)" fillcolor=lightblue]
	1966963702384 -> 1964973563600
	1964973563600 [label=AccumulateGrad]
	1964973558320 -> 1964973559472
	1966963688944 [label="bottleneck.1.0.bias
 (128)" fillcolor=lightblue]
	1966963688944 -> 1964973558320
	1964973558320 [label=AccumulateGrad]
	1964973561344 -> 1964973562496
	1966963702224 [label="decoders.0.0.weight
 (128)" fillcolor=lightblue]
	1966963702224 -> 1964973561344
	1964973561344 [label=AccumulateGrad]
	1964973558800 -> 1964973562496
	1966963688784 [label="decoders.0.0.bias
 (128)" fillcolor=lightblue]
	1966963688784 -> 1964973558800
	1964973558800 [label=AccumulateGrad]
	1964973557696 -> 1964973563888
	1966963688624 [label="decoders.0.1.0.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	1966963688624 -> 1964973557696
	1964973557696 [label=AccumulateGrad]
	1964973563840 -> 1964973563888
	1966963688544 [label="decoders.0.1.0.bias
 (128)" fillcolor=lightblue]
	1966963688544 -> 1964973563840
	1964973563840 [label=AccumulateGrad]
	1964973561104 -> 1964973558368
	1966963695264 [label="decoders.0.1.1.0.weight
 (128)" fillcolor=lightblue]
	1966963695264 -> 1964973561104
	1964973561104 [label=AccumulateGrad]
	1964973558464 -> 1964973558368
	1966963695184 [label="decoders.0.1.1.0.bias
 (128)" fillcolor=lightblue]
	1966963695184 -> 1964973558464
	1964973558464 [label=AccumulateGrad]
	1964973562256 -> 1964973465440
	1966963695024 [label="decoders.0.2.0.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	1966963695024 -> 1964973562256
	1964973562256 [label=AccumulateGrad]
	1964973560720 -> 1964973465440
	1966963701824 [label="decoders.0.2.0.bias
 (128)" fillcolor=lightblue]
	1966963701824 -> 1964973560720
	1964973560720 [label=AccumulateGrad]
	1964973469136 -> 1964973468368
	1966963701744 [label="decoders.0.2.1.0.weight
 (128)" fillcolor=lightblue]
	1966963701744 -> 1964973469136
	1964973469136 [label=AccumulateGrad]
	1964973463424 -> 1964973468368
	1966963688304 [label="decoders.0.2.1.0.bias
 (128)" fillcolor=lightblue]
	1966963688304 -> 1964973463424
	1964973463424 [label=AccumulateGrad]
	1964973458384 -> 1964973466832
	1966963701584 [label="decoders.1.0.weight
 (128)" fillcolor=lightblue]
	1966963701584 -> 1964973458384
	1964973458384 [label=AccumulateGrad]
	1964973460784 -> 1964973466832
	1966963688144 [label="decoders.1.0.bias
 (128)" fillcolor=lightblue]
	1966963688144 -> 1964973460784
	1964973460784 [label=AccumulateGrad]
	1964973472064 -> 1964973467936
	1966963687824 [label="decoders.1.1.0.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	1966963687824 -> 1964973472064
	1964973472064 [label=AccumulateGrad]
	1964973460400 -> 1964973467936
	1966963687744 [label="decoders.1.1.0.bias
 (128)" fillcolor=lightblue]
	1966963687744 -> 1964973460400
	1964973460400 [label=AccumulateGrad]
	1964973472976 -> 1964973473216
	1966963694464 [label="decoders.1.1.1.0.weight
 (128)" fillcolor=lightblue]
	1966963694464 -> 1964973472976
	1964973472976 [label=AccumulateGrad]
	1964973467120 -> 1964973473216
	1966963694384 [label="decoders.1.1.1.0.bias
 (128)" fillcolor=lightblue]
	1966963694384 -> 1964973467120
	1964973467120 [label=AccumulateGrad]
	1964973461696 -> 1964973461072
	1966963694624 [label="decoders.1.2.0.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	1966963694624 -> 1964973461696
	1964973461696 [label=AccumulateGrad]
	1964973466880 -> 1964973461072
	1966963694544 [label="decoders.1.2.0.bias
 (128)" fillcolor=lightblue]
	1966963694544 -> 1964973466880
	1964973466880 [label=AccumulateGrad]
	1964973471824 -> 1964973459776
	1966963701184 [label="decoders.1.2.1.0.weight
 (128)" fillcolor=lightblue]
	1966963701184 -> 1964973471824
	1964973471824 [label=AccumulateGrad]
	1964973462368 -> 1964973459776
	1966963701104 [label="decoders.1.2.1.0.bias
 (128)" fillcolor=lightblue]
	1966963701104 -> 1964973462368
	1964973462368 [label=AccumulateGrad]
	1964973465968 -> 1964973471296
	1966963701024 [label="decoders.2.0.weight
 (128)" fillcolor=lightblue]
	1966963701024 -> 1964973465968
	1964973465968 [label=AccumulateGrad]
	1964973460208 -> 1964973471296
	1966963700944 [label="decoders.2.0.bias
 (128)" fillcolor=lightblue]
	1966963700944 -> 1964973460208
	1964973460208 [label=AccumulateGrad]
	1964973472640 -> 1964973460688
	1966963693984 [label="decoders.2.1.0.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	1966963693984 -> 1964973472640
	1964973472640 [label=AccumulateGrad]
	1964973466784 -> 1964973460688
	1966963693904 [label="decoders.2.1.0.bias
 (128)" fillcolor=lightblue]
	1966963693904 -> 1964973466784
	1964973466784 [label=AccumulateGrad]
	1964973459440 -> 1964973461312
	1966963700544 [label="decoders.2.1.1.0.weight
 (128)" fillcolor=lightblue]
	1966963700544 -> 1964973459440
	1964973459440 [label=AccumulateGrad]
	1964973469184 -> 1964973461312
	1966963700464 [label="decoders.2.1.1.0.bias
 (128)" fillcolor=lightblue]
	1966963700464 -> 1964973469184
	1964973469184 [label=AccumulateGrad]
	1964973491344 -> 1964973506080
	1966963693424 [label="decoders.2.2.0.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	1966963693424 -> 1964973491344
	1964973491344 [label=AccumulateGrad]
	1964973505792 -> 1964973506080
	1966963700224 [label="decoders.2.2.0.bias
 (128)" fillcolor=lightblue]
	1966963700224 -> 1964973505792
	1964973505792 [label=AccumulateGrad]
	1964973497632 -> 1964973506272
	1966963700144 [label="decoders.2.2.1.0.weight
 (128)" fillcolor=lightblue]
	1966963700144 -> 1964973497632
	1964973497632 [label=AccumulateGrad]
	1964973499216 -> 1964973506272
	1966963693344 [label="decoders.2.2.1.0.bias
 (128)" fillcolor=lightblue]
	1966963693344 -> 1964973499216
	1964973499216 [label=AccumulateGrad]
	1964973504928 -> 1964973502288
	1966963693104 [label="decoders.3.0.weight
 (128)" fillcolor=lightblue]
	1966963693104 -> 1964973504928
	1964973504928 [label=AccumulateGrad]
	1964973500944 -> 1964973502288
	1966963699904 [label="decoders.3.0.bias
 (128)" fillcolor=lightblue]
	1966963699904 -> 1964973500944
	1964973500944 [label=AccumulateGrad]
	1964973505984 -> 1964973501568
	1966963692864 [label="decoders.3.1.0.weight
 (64, 128, 3, 3)" fillcolor=lightblue]
	1966963692864 -> 1964973505984
	1964973505984 [label=AccumulateGrad]
	1964973498064 -> 1964973501568
	1966963692704 [label="decoders.3.1.0.bias
 (64)" fillcolor=lightblue]
	1966963692704 -> 1964973498064
	1964973498064 [label=AccumulateGrad]
	1964973495040 -> 1964973495136
	1966963700704 [label="decoders.3.1.1.0.weight
 (64)" fillcolor=lightblue]
	1966963700704 -> 1964973495040
	1964973495040 [label=AccumulateGrad]
	1964973500224 -> 1964973495136
	1966963700624 [label="decoders.3.1.1.0.bias
 (64)" fillcolor=lightblue]
	1966963700624 -> 1964973500224
	1964973500224 [label=AccumulateGrad]
	1964973497200 -> 1964973497824
	1966963698224 [label="decoders.3.2.0.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	1966963698224 -> 1964973497200
	1964973497200 [label=AccumulateGrad]
	1964973503584 -> 1964973497824
	1967047087904 [label="decoders.3.2.0.bias
 (64)" fillcolor=lightblue]
	1967047087904 -> 1964973503584
	1964973503584 [label=AccumulateGrad]
	1964973502048 -> 1964973496048
	1967047087984 [label="decoders.3.2.1.0.weight
 (64)" fillcolor=lightblue]
	1967047087984 -> 1964973502048
	1964973502048 [label=AccumulateGrad]
	1964973491392 -> 1964973496048
	1967047088064 [label="decoders.3.2.1.0.bias
 (64)" fillcolor=lightblue]
	1967047088064 -> 1964973491392
	1964973491392 [label=AccumulateGrad]
	1964973494464 -> 1964973520304
	1967047088464 [label="decoders.4.0.weight
 (64)" fillcolor=lightblue]
	1967047088464 -> 1964973494464
	1964973494464 [label=AccumulateGrad]
	1964973504064 -> 1964973520304
	1967047088544 [label="decoders.4.0.bias
 (64)" fillcolor=lightblue]
	1967047088544 -> 1964973504064
	1964973504064 [label=AccumulateGrad]
	1964973514016 -> 1964973520832
	1967047088944 [label="decoders.4.1.0.weight
 (32, 64, 3, 3)" fillcolor=lightblue]
	1967047088944 -> 1964973514016
	1964973514016 [label=AccumulateGrad]
	1964973515552 -> 1964973520832
	1967047089024 [label="decoders.4.1.0.bias
 (32)" fillcolor=lightblue]
	1967047089024 -> 1964973515552
	1964973515552 [label=AccumulateGrad]
	1964973518672 -> 1964973516368
	1967047089104 [label="decoders.4.1.1.0.weight
 (32)" fillcolor=lightblue]
	1967047089104 -> 1964973518672
	1964973518672 [label=AccumulateGrad]
	1964973508112 -> 1964973516368
	1967047089184 [label="decoders.4.1.1.0.bias
 (32)" fillcolor=lightblue]
	1967047089184 -> 1964973508112
	1964973508112 [label=AccumulateGrad]
	1964973509360 -> 1964973511808
	1967047089584 [label="decoders.4.2.0.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	1967047089584 -> 1964973509360
	1964973509360 [label=AccumulateGrad]
	1964973513440 -> 1964973511808
	1967047089664 [label="decoders.4.2.0.bias
 (32)" fillcolor=lightblue]
	1967047089664 -> 1964973513440
	1964973513440 [label=AccumulateGrad]
	1964973516224 -> 1964973518528
	1967047089744 [label="decoders.4.2.1.0.weight
 (32)" fillcolor=lightblue]
	1967047089744 -> 1964973516224
	1964973516224 [label=AccumulateGrad]
	1964973512528 -> 1964973518528
	1967047089824 [label="decoders.4.2.1.0.bias
 (32)" fillcolor=lightblue]
	1967047089824 -> 1964973512528
	1964973512528 [label=AccumulateGrad]
	1964973515264 -> 1964973515216
	1967047090144 [label="decoders.5.0.weight
 (32)" fillcolor=lightblue]
	1967047090144 -> 1964973515264
	1964973515264 [label=AccumulateGrad]
	1964973515024 -> 1964973515216
	1967047090224 [label="decoders.5.0.bias
 (32)" fillcolor=lightblue]
	1967047090224 -> 1964973515024
	1964973515024 [label=AccumulateGrad]
	1964973516464 -> 1964973515168
	1967047090704 [label="decoders.5.1.0.weight
 (16, 32, 3, 3)" fillcolor=lightblue]
	1967047090704 -> 1964973516464
	1964973516464 [label=AccumulateGrad]
	1964973514640 -> 1964973515168
	1967047090784 [label="decoders.5.1.0.bias
 (16)" fillcolor=lightblue]
	1967047090784 -> 1964973514640
	1964973514640 [label=AccumulateGrad]
	1964973511520 -> 1964973426096
	1967047090864 [label="decoders.5.1.1.0.weight
 (16)" fillcolor=lightblue]
	1967047090864 -> 1964973511520
	1964973511520 [label=AccumulateGrad]
	1964973518288 -> 1964973426096
	1967047090944 [label="decoders.5.1.1.0.bias
 (16)" fillcolor=lightblue]
	1967047090944 -> 1964973518288
	1964973518288 [label=AccumulateGrad]
	1964973432288 -> 1964973438384
	1967047091424 [label="decoders.5.2.0.weight
 (16, 16, 3, 3)" fillcolor=lightblue]
	1967047091424 -> 1964973432288
	1964973432288 [label=AccumulateGrad]
	1964973428976 -> 1964973438384
	1967047091504 [label="decoders.5.2.0.bias
 (16)" fillcolor=lightblue]
	1967047091504 -> 1964973428976
	1964973428976 [label=AccumulateGrad]
	1964973425664 -> 1964973447856
	1967047091584 [label="decoders.5.2.1.0.weight
 (16)" fillcolor=lightblue]
	1967047091584 -> 1964973425664
	1964973425664 [label=AccumulateGrad]
	1964973435216 -> 1964973447856
	1967047091664 [label="decoders.5.2.1.0.bias
 (16)" fillcolor=lightblue]
	1967047091664 -> 1964973435216
	1964973435216 [label=AccumulateGrad]
	1964948222112 -> 1964973481488
	1967047092064 [label="final_conv.weight
 (3, 16, 1, 1)" fillcolor=lightblue]
	1967047092064 -> 1964948222112
	1964948222112 [label=AccumulateGrad]
	1964973485136 -> 1964973481488
	1967047092144 [label="final_conv.bias
 (3)" fillcolor=lightblue]
	1967047092144 -> 1964973485136
	1964973485136 [label=AccumulateGrad]
	1964973479904 -> 1967077411808
}
